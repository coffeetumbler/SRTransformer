{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/coffeetumbler/anaconda3/envs/sr_trans/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_model_summary\n",
    "\n",
    "from models.msire import MultiScaleIREncoder, DilatedWindowedIREncoder, ExpandedWindowedIREncoder\n",
    "from test import test\n",
    "from utils.dataloader import get_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "      Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "========================================================================\n",
      "          Conv2d-1     [1, 152, 64, 64]           4,256           4,256\n",
      "       LayerNorm-2     [1, 64, 64, 152]             304             304\n",
      "          Linear-3     [1, 64, 64, 152]          23,256          23,256\n",
      "    DecoderLayer-4     [1, 64, 64, 152]         478,588         478,588\n",
      "    DecoderLayer-5     [1, 64, 64, 152]         478,588         478,588\n",
      "    DecoderLayer-6     [1, 64, 64, 152]         478,588         478,588\n",
      "          Conv2d-7     [1, 456, 64, 64]          69,768          69,768\n",
      "            GELU-8     [1, 456, 64, 64]               0               0\n",
      "          Conv2d-9     [1, 456, 64, 64]           4,560           4,560\n",
      "         Conv2d-10     [1, 152, 64, 64]          69,464          69,464\n",
      "      LayerNorm-11     [1, 64, 64, 152]             304             304\n",
      "         Linear-12     [1, 64, 64, 152]          23,256          23,256\n",
      "   DecoderLayer-13     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-14     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-15     [1, 64, 64, 152]         478,588         478,588\n",
      "         Conv2d-16     [1, 456, 64, 64]          69,768          69,768\n",
      "           GELU-17     [1, 456, 64, 64]               0               0\n",
      "         Conv2d-18     [1, 456, 64, 64]           4,560           4,560\n",
      "         Conv2d-19     [1, 152, 64, 64]          69,464          69,464\n",
      "      LayerNorm-20     [1, 64, 64, 152]             304             304\n",
      "         Linear-21     [1, 64, 64, 152]          23,256          23,256\n",
      "   DecoderLayer-22     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-23     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-24     [1, 64, 64, 152]         478,588         478,588\n",
      "         Conv2d-25     [1, 456, 64, 64]          69,768          69,768\n",
      "           GELU-26     [1, 456, 64, 64]               0               0\n",
      "         Conv2d-27     [1, 456, 64, 64]           4,560           4,560\n",
      "         Conv2d-28     [1, 152, 64, 64]          69,464          69,464\n",
      "      LayerNorm-29     [1, 64, 64, 152]             304             304\n",
      "         Linear-30     [1, 64, 64, 152]          23,256          23,256\n",
      "   DecoderLayer-31     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-32     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-33     [1, 64, 64, 152]         478,588         478,588\n",
      "         Conv2d-34     [1, 456, 64, 64]          69,768          69,768\n",
      "           GELU-35     [1, 456, 64, 64]               0               0\n",
      "         Conv2d-36     [1, 456, 64, 64]           4,560           4,560\n",
      "         Conv2d-37     [1, 152, 64, 64]          69,464          69,464\n",
      "      LayerNorm-38     [1, 64, 64, 152]             304             304\n",
      "         Linear-39     [1, 64, 64, 152]          23,256          23,256\n",
      "   DecoderLayer-40     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-41     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-42     [1, 64, 64, 152]         478,588         478,588\n",
      "         Conv2d-43     [1, 456, 64, 64]          69,768          69,768\n",
      "           GELU-44     [1, 456, 64, 64]               0               0\n",
      "         Conv2d-45     [1, 456, 64, 64]           4,560           4,560\n",
      "         Conv2d-46     [1, 152, 64, 64]          69,464          69,464\n",
      "      LayerNorm-47     [1, 64, 64, 152]             304             304\n",
      "         Linear-48     [1, 64, 64, 152]          23,256          23,256\n",
      "   DecoderLayer-49     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-50     [1, 64, 64, 152]         478,588         478,588\n",
      "   DecoderLayer-51     [1, 64, 64, 152]         478,588         478,588\n",
      "         Conv2d-52     [1, 456, 64, 64]          69,768          69,768\n",
      "           GELU-53     [1, 456, 64, 64]               0               0\n",
      "         Conv2d-54     [1, 456, 64, 64]           4,560           4,560\n",
      "         Conv2d-55     [1, 152, 64, 64]          69,464          69,464\n",
      "         Conv2d-56      [1, 12, 64, 64]          32,844          32,844\n",
      "========================================================================\n",
      "Total params: 9,655,796\n",
      "Trainable params: 9,655,796\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "GFlops : 52.632059904\n"
     ]
    }
   ],
   "source": [
    "# Multi-scale IREncoder, d = 152, window = 16, layer = 3*6=18, head = 4\n",
    "device = torch.device('cuda')\n",
    "multiirencoder = MultiScaleIREncoder(img_res=64, d_embed=152, n_layer=[3,3,3,3,3,3], n_head=4,\n",
    "                                     hidden_dim_rate=3, window_size=16, sr_upscale=2, test_version=True).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(multiirencoder,\n",
    "                                    torch.zeros(1, 3, 64, 64, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', multiirencoder.flops(64, 64) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "      Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "========================================================================\n",
      "          Conv2d-1     [1, 124, 72, 72]           3,472           3,472\n",
      "       LayerNorm-2     [1, 72, 72, 124]             248             248\n",
      "          Linear-3     [1, 72, 72, 124]          15,500          15,500\n",
      "    DecoderLayer-4     [1, 72, 72, 124]         318,752         318,752\n",
      "    DecoderLayer-5     [1, 72, 72, 124]         318,752         318,752\n",
      "    DecoderLayer-6     [1, 72, 72, 124]         318,752         318,752\n",
      "    DecoderLayer-7     [1, 72, 72, 124]         318,752         318,752\n",
      "          Conv2d-8     [1, 372, 72, 72]          46,500          46,500\n",
      "            GELU-9     [1, 372, 72, 72]               0               0\n",
      "         Conv2d-10     [1, 372, 72, 72]           3,720           3,720\n",
      "         Conv2d-11     [1, 124, 72, 72]          46,252          46,252\n",
      "      LayerNorm-12     [1, 72, 72, 124]             248             248\n",
      "         Linear-13     [1, 72, 72, 124]          15,500          15,500\n",
      "   DecoderLayer-14     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-15     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-16     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-17     [1, 72, 72, 124]         318,752         318,752\n",
      "         Conv2d-18     [1, 372, 72, 72]          46,500          46,500\n",
      "           GELU-19     [1, 372, 72, 72]               0               0\n",
      "         Conv2d-20     [1, 372, 72, 72]           3,720           3,720\n",
      "         Conv2d-21     [1, 124, 72, 72]          46,252          46,252\n",
      "      LayerNorm-22     [1, 72, 72, 124]             248             248\n",
      "         Linear-23     [1, 72, 72, 124]          15,500          15,500\n",
      "   DecoderLayer-24     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-25     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-26     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-27     [1, 72, 72, 124]         318,752         318,752\n",
      "         Conv2d-28     [1, 372, 72, 72]          46,500          46,500\n",
      "           GELU-29     [1, 372, 72, 72]               0               0\n",
      "         Conv2d-30     [1, 372, 72, 72]           3,720           3,720\n",
      "         Conv2d-31     [1, 124, 72, 72]          46,252          46,252\n",
      "      LayerNorm-32     [1, 72, 72, 124]             248             248\n",
      "         Linear-33     [1, 72, 72, 124]          15,500          15,500\n",
      "   DecoderLayer-34     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-35     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-36     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-37     [1, 72, 72, 124]         318,752         318,752\n",
      "         Conv2d-38     [1, 372, 72, 72]          46,500          46,500\n",
      "           GELU-39     [1, 372, 72, 72]               0               0\n",
      "         Conv2d-40     [1, 372, 72, 72]           3,720           3,720\n",
      "         Conv2d-41     [1, 124, 72, 72]          46,252          46,252\n",
      "      LayerNorm-42     [1, 72, 72, 124]             248             248\n",
      "         Linear-43     [1, 72, 72, 124]          15,500          15,500\n",
      "   DecoderLayer-44     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-45     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-46     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-47     [1, 72, 72, 124]         318,752         318,752\n",
      "         Conv2d-48     [1, 372, 72, 72]          46,500          46,500\n",
      "           GELU-49     [1, 372, 72, 72]               0               0\n",
      "         Conv2d-50     [1, 372, 72, 72]           3,720           3,720\n",
      "         Conv2d-51     [1, 124, 72, 72]          46,252          46,252\n",
      "      LayerNorm-52     [1, 72, 72, 124]             248             248\n",
      "         Linear-53     [1, 72, 72, 124]          15,500          15,500\n",
      "   DecoderLayer-54     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-55     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-56     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-57     [1, 72, 72, 124]         318,752         318,752\n",
      "         Conv2d-58     [1, 372, 72, 72]          46,500          46,500\n",
      "           GELU-59     [1, 372, 72, 72]               0               0\n",
      "         Conv2d-60     [1, 372, 72, 72]           3,720           3,720\n",
      "         Conv2d-61     [1, 124, 72, 72]          46,252          46,252\n",
      "      LayerNorm-62     [1, 72, 72, 124]             248             248\n",
      "         Linear-63     [1, 72, 72, 124]          15,500          15,500\n",
      "   DecoderLayer-64     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-65     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-66     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-67     [1, 72, 72, 124]         318,752         318,752\n",
      "         Conv2d-68     [1, 372, 72, 72]          46,500          46,500\n",
      "           GELU-69     [1, 372, 72, 72]               0               0\n",
      "         Conv2d-70     [1, 372, 72, 72]           3,720           3,720\n",
      "         Conv2d-71     [1, 124, 72, 72]          46,252          46,252\n",
      "      LayerNorm-72     [1, 72, 72, 124]             248             248\n",
      "         Linear-73     [1, 72, 72, 124]          15,500          15,500\n",
      "   DecoderLayer-74     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-75     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-76     [1, 72, 72, 124]         318,752         318,752\n",
      "   DecoderLayer-77     [1, 72, 72, 124]         318,752         318,752\n",
      "         Conv2d-78     [1, 372, 72, 72]          46,500          46,500\n",
      "           GELU-79     [1, 372, 72, 72]               0               0\n",
      "         Conv2d-80     [1, 372, 72, 72]           3,720           3,720\n",
      "         Conv2d-81     [1, 124, 72, 72]          46,252          46,252\n",
      "         Conv2d-82      [1, 12, 72, 72]          26,796          26,796\n",
      "========================================================================\n",
      "Total params: 11,128,092\n",
      "Trainable params: 11,128,092\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "GFlops : 54.847029248\n"
     ]
    }
   ],
   "source": [
    "# Multi-scale IREncoder, d = 124, window = 12, layer = 4*8=32, head = 4\n",
    "device = torch.device('cuda')\n",
    "multiirencoder = MultiScaleIREncoder(img_res=72, d_embed=124, n_layer=[4,4,4,4,4,4,4,4], n_head=4,\n",
    "                                     hidden_dim_rate=3, window_size=12, sr_upscale=2, test_version=True).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(multiirencoder,\n",
    "                                    torch.zeros(1, 3, 72, 72, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', multiirencoder.flops(64, 64) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "      Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "========================================================================\n",
      "          Conv2d-1     [1, 136, 56, 56]           3,808           3,808\n",
      "       LayerNorm-2     [1, 56, 56, 136]             272             272\n",
      "          Linear-3     [1, 56, 56, 136]          18,632          18,632\n",
      "    DecoderLayer-4     [1, 56, 56, 136]         384,332         384,332\n",
      "    DecoderLayer-5     [1, 56, 56, 136]         384,332         384,332\n",
      "    DecoderLayer-6     [1, 56, 56, 136]         384,332         384,332\n",
      "    DecoderLayer-7     [1, 56, 56, 136]         384,332         384,332\n",
      "          Conv2d-8     [1, 408, 56, 56]          55,896          55,896\n",
      "            GELU-9     [1, 408, 56, 56]               0               0\n",
      "         Conv2d-10     [1, 408, 56, 56]           4,080           4,080\n",
      "         Conv2d-11     [1, 136, 56, 56]          55,624          55,624\n",
      "      LayerNorm-12     [1, 56, 56, 136]             272             272\n",
      "         Linear-13     [1, 56, 56, 136]          18,632          18,632\n",
      "   DecoderLayer-14     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-15     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-16     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-17     [1, 56, 56, 136]         384,332         384,332\n",
      "         Conv2d-18     [1, 408, 56, 56]          55,896          55,896\n",
      "           GELU-19     [1, 408, 56, 56]               0               0\n",
      "         Conv2d-20     [1, 408, 56, 56]           4,080           4,080\n",
      "         Conv2d-21     [1, 136, 56, 56]          55,624          55,624\n",
      "      LayerNorm-22     [1, 56, 56, 136]             272             272\n",
      "         Linear-23     [1, 56, 56, 136]          18,632          18,632\n",
      "   DecoderLayer-24     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-25     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-26     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-27     [1, 56, 56, 136]         384,332         384,332\n",
      "         Conv2d-28     [1, 408, 56, 56]          55,896          55,896\n",
      "           GELU-29     [1, 408, 56, 56]               0               0\n",
      "         Conv2d-30     [1, 408, 56, 56]           4,080           4,080\n",
      "         Conv2d-31     [1, 136, 56, 56]          55,624          55,624\n",
      "      LayerNorm-32     [1, 56, 56, 136]             272             272\n",
      "         Linear-33     [1, 56, 56, 136]          18,632          18,632\n",
      "   DecoderLayer-34     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-35     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-36     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-37     [1, 56, 56, 136]         384,332         384,332\n",
      "         Conv2d-38     [1, 408, 56, 56]          55,896          55,896\n",
      "           GELU-39     [1, 408, 56, 56]               0               0\n",
      "         Conv2d-40     [1, 408, 56, 56]           4,080           4,080\n",
      "         Conv2d-41     [1, 136, 56, 56]          55,624          55,624\n",
      "      LayerNorm-42     [1, 56, 56, 136]             272             272\n",
      "         Linear-43     [1, 56, 56, 136]          18,632          18,632\n",
      "   DecoderLayer-44     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-45     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-46     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-47     [1, 56, 56, 136]         384,332         384,332\n",
      "         Conv2d-48     [1, 408, 56, 56]          55,896          55,896\n",
      "           GELU-49     [1, 408, 56, 56]               0               0\n",
      "         Conv2d-50     [1, 408, 56, 56]           4,080           4,080\n",
      "         Conv2d-51     [1, 136, 56, 56]          55,624          55,624\n",
      "      LayerNorm-52     [1, 56, 56, 136]             272             272\n",
      "         Linear-53     [1, 56, 56, 136]          18,632          18,632\n",
      "   DecoderLayer-54     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-55     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-56     [1, 56, 56, 136]         384,332         384,332\n",
      "   DecoderLayer-57     [1, 56, 56, 136]         384,332         384,332\n",
      "         Conv2d-58     [1, 408, 56, 56]          55,896          55,896\n",
      "           GELU-59     [1, 408, 56, 56]               0               0\n",
      "         Conv2d-60     [1, 408, 56, 56]           4,080           4,080\n",
      "         Conv2d-61     [1, 136, 56, 56]          55,624          55,624\n",
      "         Conv2d-62      [1, 12, 56, 56]          29,388          29,388\n",
      "========================================================================\n",
      "Total params: 10,064,188\n",
      "Trainable params: 10,064,188\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "GFlops : 52.489715712\n"
     ]
    }
   ],
   "source": [
    "# Multi-scale IREncoder, d = 124, window = 12, layer = 4*8=32, head = 4\n",
    "device = torch.device('cuda')\n",
    "multiirencoder = MultiScaleIREncoder(img_res=56, d_embed=136, n_layer=[4,4,4,4,4,4], n_head=4,\n",
    "                                     hidden_dim_rate=3, window_size=14, sr_upscale=2, test_version=True).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(multiirencoder,\n",
    "                                    torch.zeros(1, 3, 56, 56, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', multiirencoder.flops(64, 64) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------\n",
      "      Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "========================================================================\n",
      "          Conv2d-1      [1, 46, 60, 60]           1,288           1,288\n",
      "       LayerNorm-2      [1, 60, 60, 46]              92              92\n",
      "          Linear-3      [1, 60, 60, 46]           2,162           2,162\n",
      "    DecoderLayer-4      [1, 60, 60, 46]          53,096          53,096\n",
      "    DecoderLayer-5      [1, 60, 60, 46]          53,096          53,096\n",
      "    DecoderLayer-6      [1, 60, 60, 46]          53,096          53,096\n",
      "          Conv2d-7     [1, 138, 60, 60]           6,486           6,486\n",
      "            GELU-8     [1, 138, 60, 60]               0               0\n",
      "          Conv2d-9     [1, 138, 60, 60]           1,380           1,380\n",
      "         Conv2d-10      [1, 46, 60, 60]           6,394           6,394\n",
      "      LayerNorm-11      [1, 60, 60, 46]              92              92\n",
      "         Linear-12      [1, 60, 60, 46]           2,162           2,162\n",
      "   DecoderLayer-13      [1, 60, 60, 46]          53,096          53,096\n",
      "   DecoderLayer-14      [1, 60, 60, 46]          53,096          53,096\n",
      "   DecoderLayer-15      [1, 60, 60, 46]          53,096          53,096\n",
      "         Conv2d-16     [1, 138, 60, 60]           6,486           6,486\n",
      "           GELU-17     [1, 138, 60, 60]               0               0\n",
      "         Conv2d-18     [1, 138, 60, 60]           1,380           1,380\n",
      "         Conv2d-19      [1, 46, 60, 60]           6,394           6,394\n",
      "      LayerNorm-20      [1, 60, 60, 46]              92              92\n",
      "         Linear-21      [1, 60, 60, 46]           2,162           2,162\n",
      "   DecoderLayer-22      [1, 60, 60, 46]          53,096          53,096\n",
      "   DecoderLayer-23      [1, 60, 60, 46]          53,096          53,096\n",
      "   DecoderLayer-24      [1, 60, 60, 46]          53,096          53,096\n",
      "         Conv2d-25     [1, 138, 60, 60]           6,486           6,486\n",
      "           GELU-26     [1, 138, 60, 60]               0               0\n",
      "         Conv2d-27     [1, 138, 60, 60]           1,380           1,380\n",
      "         Conv2d-28      [1, 46, 60, 60]           6,394           6,394\n",
      "      LayerNorm-29      [1, 60, 60, 46]              92              92\n",
      "         Linear-30      [1, 60, 60, 46]           2,162           2,162\n",
      "   DecoderLayer-31      [1, 60, 60, 46]          53,096          53,096\n",
      "   DecoderLayer-32      [1, 60, 60, 46]          53,096          53,096\n",
      "   DecoderLayer-33      [1, 60, 60, 46]          53,096          53,096\n",
      "         Conv2d-34     [1, 138, 60, 60]           6,486           6,486\n",
      "           GELU-35     [1, 138, 60, 60]               0               0\n",
      "         Conv2d-36     [1, 138, 60, 60]           1,380           1,380\n",
      "         Conv2d-37      [1, 46, 60, 60]           6,394           6,394\n",
      "         Conv2d-38      [1, 12, 60, 60]           9,948           9,948\n",
      "========================================================================\n",
      "Total params: 714,444\n",
      "Trainable params: 714,444\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------\n",
      "GFlops : 205.0048512\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Multi-scale IREncoder, d = 46, window = 10, layer = 3*4=12, head = 2\n",
    "device = torch.device('cuda')\n",
    "multiirencoder = MultiScaleIREncoder(img_res=60, d_embed=46, n_layer=[3,3,3,3], n_head=2,\n",
    "                                     hidden_dim_rate=3, window_size=10, sr_upscale=2, test_version=True).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(multiirencoder,\n",
    "                                    torch.zeros(1, 3, 60, 60, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', multiirencoder.flops(640, 360) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Conv2d-1     [1, 46, 48, 48]           1,288           1,288\n",
      "       LayerNorm-2     [1, 48, 48, 46]              92              92\n",
      "          Linear-3     [1, 48, 48, 46]           2,162           2,162\n",
      "    DecoderLayer-4     [1, 48, 48, 46]          45,910          45,910\n",
      "    DecoderLayer-5     [1, 48, 48, 46]          45,910          45,910\n",
      "    DecoderLayer-6     [1, 48, 48, 46]          45,910          45,910\n",
      "    DecoderLayer-7     [1, 48, 48, 46]          45,910          45,910\n",
      "          Conv2d-8     [1, 92, 48, 48]           4,324           4,324\n",
      "            GELU-9     [1, 92, 48, 48]               0               0\n",
      "         Conv2d-10     [1, 92, 48, 48]             920             920\n",
      "         Conv2d-11     [1, 46, 48, 48]           4,278           4,278\n",
      "      LayerNorm-12     [1, 48, 48, 46]              92              92\n",
      "         Linear-13     [1, 48, 48, 46]           2,162           2,162\n",
      "   DecoderLayer-14     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-15     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-16     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-17     [1, 48, 48, 46]          45,910          45,910\n",
      "         Conv2d-18     [1, 92, 48, 48]           4,324           4,324\n",
      "           GELU-19     [1, 92, 48, 48]               0               0\n",
      "         Conv2d-20     [1, 92, 48, 48]             920             920\n",
      "         Conv2d-21     [1, 46, 48, 48]           4,278           4,278\n",
      "      LayerNorm-22     [1, 48, 48, 46]              92              92\n",
      "         Linear-23     [1, 48, 48, 46]           2,162           2,162\n",
      "   DecoderLayer-24     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-25     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-26     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-27     [1, 48, 48, 46]          45,910          45,910\n",
      "         Conv2d-28     [1, 92, 48, 48]           4,324           4,324\n",
      "           GELU-29     [1, 92, 48, 48]               0               0\n",
      "         Conv2d-30     [1, 92, 48, 48]             920             920\n",
      "         Conv2d-31     [1, 46, 48, 48]           4,278           4,278\n",
      "      LayerNorm-32     [1, 48, 48, 46]              92              92\n",
      "         Linear-33     [1, 48, 48, 46]           2,162           2,162\n",
      "   DecoderLayer-34     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-35     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-36     [1, 48, 48, 46]          45,910          45,910\n",
      "   DecoderLayer-37     [1, 48, 48, 46]          45,910          45,910\n",
      "         Conv2d-38     [1, 92, 48, 48]           4,324           4,324\n",
      "           GELU-39     [1, 92, 48, 48]               0               0\n",
      "         Conv2d-40     [1, 92, 48, 48]             920             920\n",
      "         Conv2d-41     [1, 46, 48, 48]           4,278           4,278\n",
      "         Conv2d-42     [1, 12, 48, 48]           9,948           9,948\n",
      "=======================================================================\n",
      "Total params: 792,900\n",
      "Trainable params: 792,900\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "GFlops : 209.4985728\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Multi-scale IREncoder, d = 46, window = 8, layer = 4*4=16, head = 2\n",
    "device = torch.device('cuda')\n",
    "multiirencoder = MultiScaleIREncoder(img_res=48, d_embed=46, n_layer=[4,4,4,4], n_head=2,\n",
    "                                     hidden_dim_rate=2, window_size=8, sr_upscale=2, test_version=True).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(multiirencoder,\n",
    "                                    torch.zeros(1, 3, 48, 48, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', multiirencoder.flops(640, 360) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1     [1, 128, 64, 64]           3,584           3,584\n",
      "             LayerNorm-2     [1, 64, 64, 128]             256             256\n",
      "                Linear-3     [1, 64, 64, 128]          16,512          16,512\n",
      "    TransformerEncoder-4     [1, 64, 64, 128]       1,310,256       1,310,256\n",
      "                Conv2d-5     [1, 512, 64, 64]          66,048          66,048\n",
      "                  GELU-6     [1, 512, 64, 64]               0               0\n",
      "                Conv2d-7     [1, 512, 64, 64]           5,120           5,120\n",
      "                Conv2d-8     [1, 128, 64, 64]          65,664          65,664\n",
      "             LayerNorm-9     [1, 64, 64, 128]             256             256\n",
      "               Linear-10     [1, 64, 64, 128]          16,512          16,512\n",
      "   TransformerEncoder-11     [1, 64, 64, 128]       1,310,256       1,310,256\n",
      "               Conv2d-12     [1, 512, 64, 64]          66,048          66,048\n",
      "                 GELU-13     [1, 512, 64, 64]               0               0\n",
      "               Conv2d-14     [1, 512, 64, 64]           5,120           5,120\n",
      "               Conv2d-15     [1, 128, 64, 64]          65,664          65,664\n",
      "            LayerNorm-16     [1, 64, 64, 128]             256             256\n",
      "               Linear-17     [1, 64, 64, 128]          16,512          16,512\n",
      "   TransformerEncoder-18     [1, 64, 64, 128]       1,310,256       1,310,256\n",
      "               Conv2d-19     [1, 512, 64, 64]          66,048          66,048\n",
      "                 GELU-20     [1, 512, 64, 64]               0               0\n",
      "               Conv2d-21     [1, 512, 64, 64]           5,120           5,120\n",
      "               Conv2d-22     [1, 128, 64, 64]          65,664          65,664\n",
      "            LayerNorm-23     [1, 64, 64, 128]             256             256\n",
      "               Linear-24     [1, 64, 64, 128]          16,512          16,512\n",
      "   TransformerEncoder-25     [1, 64, 64, 128]       1,310,256       1,310,256\n",
      "               Conv2d-26     [1, 512, 64, 64]          66,048          66,048\n",
      "                 GELU-27     [1, 512, 64, 64]               0               0\n",
      "               Conv2d-28     [1, 512, 64, 64]           5,120           5,120\n",
      "               Conv2d-29     [1, 128, 64, 64]          65,664          65,664\n",
      "            LayerNorm-30     [1, 64, 64, 128]             256             256\n",
      "               Linear-31     [1, 64, 64, 128]          16,512          16,512\n",
      "   TransformerEncoder-32     [1, 64, 64, 128]       1,310,256       1,310,256\n",
      "               Conv2d-33     [1, 512, 64, 64]          66,048          66,048\n",
      "                 GELU-34     [1, 512, 64, 64]               0               0\n",
      "               Conv2d-35     [1, 512, 64, 64]           5,120           5,120\n",
      "               Conv2d-36     [1, 128, 64, 64]          65,664          65,664\n",
      "            LayerNorm-37     [1, 64, 64, 128]             256             256\n",
      "               Linear-38     [1, 64, 64, 128]          16,512          16,512\n",
      "   TransformerEncoder-39     [1, 64, 64, 128]       1,310,256       1,310,256\n",
      "               Conv2d-40     [1, 512, 64, 64]          66,048          66,048\n",
      "                 GELU-41     [1, 512, 64, 64]               0               0\n",
      "               Conv2d-42     [1, 512, 64, 64]           5,120           5,120\n",
      "               Conv2d-43     [1, 128, 64, 64]          65,664          65,664\n",
      "               Conv2d-44      [1, 12, 64, 64]          27,660          27,660\n",
      "==============================================================================\n",
      "Total params: 8,814,380\n",
      "Trainable params: 8,814,380\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 53.922496512\n"
     ]
    }
   ],
   "source": [
    "# Dilated-windowed IREncoder, d = 128, window = 16, layer = 6*6=36, head = 8\n",
    "device = torch.device('cuda')\n",
    "irencoder = DilatedWindowedIREncoder(img_res=64, d_embed=128, n_layer=[6,6,6,6,6,6], n_head=8,\n",
    "                                     hidden_dim_rate=2, conv_hidden_rate=2, window_size=16, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 64, 64, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(64, 64) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1      [1, 42, 64, 64]           1,176           1,176\n",
      "             LayerNorm-2      [1, 64, 64, 42]              84              84\n",
      "                Linear-3      [1, 64, 64, 42]           1,806           1,806\n",
      "    TransformerEncoder-4      [1, 64, 64, 42]         162,828         162,828\n",
      "                Conv2d-5     [1, 168, 64, 64]           7,224           7,224\n",
      "                  GELU-6     [1, 168, 64, 64]               0               0\n",
      "                Conv2d-7     [1, 168, 64, 64]           1,680           1,680\n",
      "                Conv2d-8      [1, 42, 64, 64]           7,098           7,098\n",
      "             LayerNorm-9      [1, 64, 64, 42]              84              84\n",
      "               Linear-10      [1, 64, 64, 42]           1,806           1,806\n",
      "   TransformerEncoder-11      [1, 64, 64, 42]         162,828         162,828\n",
      "               Conv2d-12     [1, 168, 64, 64]           7,224           7,224\n",
      "                 GELU-13     [1, 168, 64, 64]               0               0\n",
      "               Conv2d-14     [1, 168, 64, 64]           1,680           1,680\n",
      "               Conv2d-15      [1, 42, 64, 64]           7,098           7,098\n",
      "            LayerNorm-16      [1, 64, 64, 42]              84              84\n",
      "               Linear-17      [1, 64, 64, 42]           1,806           1,806\n",
      "   TransformerEncoder-18      [1, 64, 64, 42]         162,828         162,828\n",
      "               Conv2d-19     [1, 168, 64, 64]           7,224           7,224\n",
      "                 GELU-20     [1, 168, 64, 64]               0               0\n",
      "               Conv2d-21     [1, 168, 64, 64]           1,680           1,680\n",
      "               Conv2d-22      [1, 42, 64, 64]           7,098           7,098\n",
      "            LayerNorm-23      [1, 64, 64, 42]              84              84\n",
      "               Linear-24      [1, 64, 64, 42]           1,806           1,806\n",
      "   TransformerEncoder-25      [1, 64, 64, 42]         162,828         162,828\n",
      "               Conv2d-26     [1, 168, 64, 64]           7,224           7,224\n",
      "                 GELU-27     [1, 168, 64, 64]               0               0\n",
      "               Conv2d-28     [1, 168, 64, 64]           1,680           1,680\n",
      "               Conv2d-29      [1, 42, 64, 64]           7,098           7,098\n",
      "               Conv2d-30      [1, 12, 64, 64]           9,084           9,084\n",
      "==============================================================================\n",
      "Total params: 733,140\n",
      "Trainable params: 733,140\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 216.2861568\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Dilated-windowed IREncoder, d = 32, window = 12, layer = 4*6=24, head = 4\n",
    "device = torch.device('cuda')\n",
    "irencoder = DilatedWindowedIREncoder(img_res=64, d_embed=42, n_layer=[6,6,6,6], n_head=6,\n",
    "                                     hidden_dim_rate=2, conv_hidden_rate=2, window_size=8, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 64, 64, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(640, 360) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1     [1, 144, 64, 64]           4,032           4,032\n",
      "             LayerNorm-2     [1, 64, 64, 144]             288             288\n",
      "                Linear-3     [1, 64, 64, 144]          20,880          20,880\n",
      "    TransformerEncoder-4     [1, 64, 64, 144]       1,737,984       1,737,984\n",
      "                Conv2d-5     [1, 576, 64, 64]          83,520          83,520\n",
      "                  GELU-6     [1, 576, 64, 64]               0               0\n",
      "                Conv2d-7     [1, 576, 64, 64]           5,760           5,760\n",
      "                Conv2d-8     [1, 144, 64, 64]          83,088          83,088\n",
      "             LayerNorm-9     [1, 64, 64, 144]             288             288\n",
      "               Linear-10     [1, 64, 64, 144]          20,880          20,880\n",
      "   TransformerEncoder-11     [1, 64, 64, 144]       1,737,984       1,737,984\n",
      "               Conv2d-12     [1, 576, 64, 64]          83,520          83,520\n",
      "                 GELU-13     [1, 576, 64, 64]               0               0\n",
      "               Conv2d-14     [1, 576, 64, 64]           5,760           5,760\n",
      "               Conv2d-15     [1, 144, 64, 64]          83,088          83,088\n",
      "            LayerNorm-16     [1, 64, 64, 144]             288             288\n",
      "               Linear-17     [1, 64, 64, 144]          20,880          20,880\n",
      "   TransformerEncoder-18     [1, 64, 64, 144]       1,737,984       1,737,984\n",
      "               Conv2d-19     [1, 576, 64, 64]          83,520          83,520\n",
      "                 GELU-20     [1, 576, 64, 64]               0               0\n",
      "               Conv2d-21     [1, 576, 64, 64]           5,760           5,760\n",
      "               Conv2d-22     [1, 144, 64, 64]          83,088          83,088\n",
      "            LayerNorm-23     [1, 64, 64, 144]             288             288\n",
      "               Linear-24     [1, 64, 64, 144]          20,880          20,880\n",
      "   TransformerEncoder-25     [1, 64, 64, 144]       1,737,984       1,737,984\n",
      "               Conv2d-26     [1, 576, 64, 64]          83,520          83,520\n",
      "                 GELU-27     [1, 576, 64, 64]               0               0\n",
      "               Conv2d-28     [1, 576, 64, 64]           5,760           5,760\n",
      "               Conv2d-29     [1, 144, 64, 64]          83,088          83,088\n",
      "            LayerNorm-30     [1, 64, 64, 144]             288             288\n",
      "               Linear-31     [1, 64, 64, 144]          20,880          20,880\n",
      "   TransformerEncoder-32     [1, 64, 64, 144]       1,737,984       1,737,984\n",
      "               Conv2d-33     [1, 576, 64, 64]          83,520          83,520\n",
      "                 GELU-34     [1, 576, 64, 64]               0               0\n",
      "               Conv2d-35     [1, 576, 64, 64]           5,760           5,760\n",
      "               Conv2d-36     [1, 144, 64, 64]          83,088          83,088\n",
      "               Conv2d-37      [1, 12, 64, 64]          31,116          31,116\n",
      "==============================================================================\n",
      "Total params: 9,692,748\n",
      "Trainable params: 9,692,748\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 53.690499072\n"
     ]
    }
   ],
   "source": [
    "# Expanded-windowed IREncoder, d = 144, window = 16, layer = 6*5=30, head = 8\n",
    "device = torch.device('cuda')\n",
    "irencoder = ExpandedWindowedIREncoder(img_res=64, d_embed=144, n_layer=[6,6,6,6,6], n_head=8,\n",
    "                                      hidden_dim_rate=2, conv_hidden_rate=2, window_size=16, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 64, 64, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(64, 64) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1     [1, 160, 64, 64]           4,480           4,480\n",
      "             LayerNorm-2     [1, 64, 64, 160]             320             320\n",
      "                Linear-3     [1, 64, 64, 160]          25,760          25,760\n",
      "    TransformerEncoder-4     [1, 64, 64, 160]       1,559,616       1,559,616\n",
      "                Conv2d-5     [1, 640, 64, 64]         103,040         103,040\n",
      "                  GELU-6     [1, 640, 64, 64]               0               0\n",
      "                Conv2d-7     [1, 640, 64, 64]           6,400           6,400\n",
      "                Conv2d-8     [1, 160, 64, 64]         102,560         102,560\n",
      "             LayerNorm-9     [1, 64, 64, 160]             320             320\n",
      "               Linear-10     [1, 64, 64, 160]          25,760          25,760\n",
      "   TransformerEncoder-11     [1, 64, 64, 160]       1,559,616       1,559,616\n",
      "               Conv2d-12     [1, 640, 64, 64]         103,040         103,040\n",
      "               Conv2d-13     [1, 640, 64, 64]           6,400           6,400\n",
      "               Conv2d-14     [1, 160, 64, 64]         102,560         102,560\n",
      "            LayerNorm-15     [1, 64, 64, 160]             320             320\n",
      "               Linear-16     [1, 64, 64, 160]          25,760          25,760\n",
      "   TransformerEncoder-17     [1, 64, 64, 160]       1,559,616       1,559,616\n",
      "               Conv2d-18     [1, 640, 64, 64]         103,040         103,040\n",
      "               Conv2d-19     [1, 640, 64, 64]           6,400           6,400\n",
      "               Conv2d-20     [1, 160, 64, 64]         102,560         102,560\n",
      "            LayerNorm-21     [1, 64, 64, 160]             320             320\n",
      "               Linear-22     [1, 64, 64, 160]          25,760          25,760\n",
      "   TransformerEncoder-23     [1, 64, 64, 160]       1,559,616       1,559,616\n",
      "               Conv2d-24     [1, 640, 64, 64]         103,040         103,040\n",
      "               Conv2d-25     [1, 640, 64, 64]           6,400           6,400\n",
      "               Conv2d-26     [1, 160, 64, 64]         102,560         102,560\n",
      "            LayerNorm-27     [1, 64, 64, 160]             320             320\n",
      "               Linear-28     [1, 64, 64, 160]          25,760          25,760\n",
      "   TransformerEncoder-29     [1, 64, 64, 160]       1,559,616       1,559,616\n",
      "               Conv2d-30     [1, 640, 64, 64]         103,040         103,040\n",
      "               Conv2d-31     [1, 640, 64, 64]           6,400           6,400\n",
      "               Conv2d-32     [1, 160, 64, 64]         102,560         102,560\n",
      "            LayerNorm-33     [1, 64, 64, 160]             320             320\n",
      "               Linear-34     [1, 64, 64, 160]          25,760          25,760\n",
      "   TransformerEncoder-35     [1, 64, 64, 160]       1,559,616       1,559,616\n",
      "               Conv2d-36     [1, 640, 64, 64]         103,040         103,040\n",
      "               Conv2d-37     [1, 640, 64, 64]           6,400           6,400\n",
      "               Conv2d-38     [1, 160, 64, 64]         102,560         102,560\n",
      "               Conv2d-39      [1, 12, 64, 64]          34,572          34,572\n",
      "==============================================================================\n",
      "Total params: 10,825,228\n",
      "Trainable params: 10,825,228\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 54.606299136\n"
     ]
    }
   ],
   "source": [
    "# Expanded-windowed IREncoder, d = 160, window = 16, layer = 6*6=36, head = 8\n",
    "device = torch.device('cuda')\n",
    "irencoder = ExpandedWindowedIREncoder(img_res=64, d_embed=160, n_layer=[6,6,6,6,6,6], n_head=8,\n",
    "                                      hidden_dim_rate=2, conv_hidden_rate=1.2, window_size=16, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 64, 64, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(64, 64) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1     [1, 192, 64, 64]           5,376           5,376\n",
      "             LayerNorm-2     [1, 64, 64, 192]             384             384\n",
      "                Linear-3     [1, 64, 64, 144]          27,792          27,792\n",
      "    TransformerEncoder-4     [1, 64, 64, 144]       1,155,312       1,155,312\n",
      "                Conv2d-5     [1, 576, 64, 64]          83,520          83,520\n",
      "                  GELU-6     [1, 576, 64, 64]               0               0\n",
      "                Conv2d-7     [1, 576, 64, 64]           5,760           5,760\n",
      "                Conv2d-8     [1, 192, 64, 64]         110,784         110,784\n",
      "             LayerNorm-9     [1, 64, 64, 192]             384             384\n",
      "               Linear-10     [1, 64, 64, 144]          27,792          27,792\n",
      "   TransformerEncoder-11     [1, 64, 64, 144]       1,155,312       1,155,312\n",
      "               Conv2d-12     [1, 576, 64, 64]          83,520          83,520\n",
      "               Conv2d-13     [1, 576, 64, 64]           5,760           5,760\n",
      "               Conv2d-14     [1, 192, 64, 64]         110,784         110,784\n",
      "            LayerNorm-15     [1, 64, 64, 192]             384             384\n",
      "               Linear-16     [1, 64, 64, 168]          32,424          32,424\n",
      "   TransformerEncoder-17     [1, 64, 64, 168]       1,528,704       1,528,704\n",
      "               Conv2d-18     [1, 672, 64, 64]         113,568         113,568\n",
      "               Conv2d-19     [1, 672, 64, 64]           6,720           6,720\n",
      "               Conv2d-20     [1, 192, 64, 64]         129,216         129,216\n",
      "            LayerNorm-21     [1, 64, 64, 192]             384             384\n",
      "               Linear-22     [1, 64, 64, 168]          32,424          32,424\n",
      "   TransformerEncoder-23     [1, 64, 64, 168]       1,528,704       1,528,704\n",
      "               Conv2d-24     [1, 672, 64, 64]         113,568         113,568\n",
      "               Conv2d-25     [1, 672, 64, 64]           6,720           6,720\n",
      "               Conv2d-26     [1, 192, 64, 64]         129,216         129,216\n",
      "            LayerNorm-27     [1, 64, 64, 192]             384             384\n",
      "               Linear-28     [1, 64, 64, 192]          37,056          37,056\n",
      "   TransformerEncoder-29     [1, 64, 64, 192]       1,957,392       1,957,392\n",
      "               Conv2d-30     [1, 768, 64, 64]         148,224         148,224\n",
      "               Conv2d-31     [1, 768, 64, 64]           7,680           7,680\n",
      "               Conv2d-32     [1, 192, 64, 64]         147,648         147,648\n",
      "            LayerNorm-33     [1, 64, 64, 192]             384             384\n",
      "               Linear-34     [1, 64, 64, 192]          37,056          37,056\n",
      "   TransformerEncoder-35     [1, 64, 64, 192]       1,957,392       1,957,392\n",
      "               Conv2d-36     [1, 768, 64, 64]         148,224         148,224\n",
      "               Conv2d-37     [1, 768, 64, 64]           7,680           7,680\n",
      "               Conv2d-38     [1, 192, 64, 64]         147,648         147,648\n",
      "               Conv2d-39      [1, 12, 64, 64]          41,484          41,484\n",
      "==============================================================================\n",
      "Total params: 11,032,764\n",
      "Trainable params: 11,032,764\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 54.443114496\n"
     ]
    }
   ],
   "source": [
    "# Expanded-windowed IREncoder, d = 144, window = 12, layer = 6*6=36, head = 8\n",
    "device = torch.device('cuda')\n",
    "irencoder = ExpandedWindowedIREncoder(img_res=64, d_embed=[144,144,168,168,192,192], n_layer=[6,6,6,6,6,6], n_head=6,\n",
    "                                      hidden_dim_rate=2, conv_hidden_rate=1, window_size=16, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 64, 64, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(64, 64) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1      [1, 42, 64, 64]           1,176           1,176\n",
      "             LayerNorm-2      [1, 64, 64, 42]              84              84\n",
      "                Linear-3      [1, 64, 64, 42]           1,806           1,806\n",
      "    TransformerEncoder-4      [1, 64, 64, 42]         180,456         180,456\n",
      "                Conv2d-5     [1, 168, 64, 64]           7,224           7,224\n",
      "                  GELU-6     [1, 168, 64, 64]               0               0\n",
      "                Conv2d-7     [1, 168, 64, 64]           1,680           1,680\n",
      "                Conv2d-8      [1, 42, 64, 64]           7,098           7,098\n",
      "             LayerNorm-9      [1, 64, 64, 42]              84              84\n",
      "               Linear-10      [1, 64, 64, 42]           1,806           1,806\n",
      "   TransformerEncoder-11      [1, 64, 64, 42]         180,456         180,456\n",
      "               Conv2d-12     [1, 168, 64, 64]           7,224           7,224\n",
      "                 GELU-13     [1, 168, 64, 64]               0               0\n",
      "               Conv2d-14     [1, 168, 64, 64]           1,680           1,680\n",
      "               Conv2d-15      [1, 42, 64, 64]           7,098           7,098\n",
      "            LayerNorm-16      [1, 64, 64, 42]              84              84\n",
      "               Linear-17      [1, 64, 64, 42]           1,806           1,806\n",
      "   TransformerEncoder-18      [1, 64, 64, 42]         180,456         180,456\n",
      "               Conv2d-19     [1, 168, 64, 64]           7,224           7,224\n",
      "                 GELU-20     [1, 168, 64, 64]               0               0\n",
      "               Conv2d-21     [1, 168, 64, 64]           1,680           1,680\n",
      "               Conv2d-22      [1, 42, 64, 64]           7,098           7,098\n",
      "            LayerNorm-23      [1, 64, 64, 42]              84              84\n",
      "               Linear-24      [1, 64, 64, 42]           1,806           1,806\n",
      "   TransformerEncoder-25      [1, 64, 64, 42]         180,456         180,456\n",
      "               Conv2d-26     [1, 168, 64, 64]           7,224           7,224\n",
      "                 GELU-27     [1, 168, 64, 64]               0               0\n",
      "               Conv2d-28     [1, 168, 64, 64]           1,680           1,680\n",
      "               Conv2d-29      [1, 42, 64, 64]           7,098           7,098\n",
      "               Conv2d-30      [1, 12, 64, 64]           9,084           9,084\n",
      "==============================================================================\n",
      "Total params: 803,652\n",
      "Trainable params: 803,652\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 206.9964288\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Expanded-windowed IREncoder, d = 42, window = 8, layer = 6*4=24, head = 4\n",
    "device = torch.device('cuda')\n",
    "irencoder = ExpandedWindowedIREncoder(img_res=64, d_embed=42, n_layer=[6,6,6,6], n_head=4,\n",
    "                                      hidden_dim_rate=2, conv_hidden_rate=2, window_size=8, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 64, 64, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(640, 360) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1      [1, 56, 60, 60]           1,568           1,568\n",
      "             LayerNorm-2      [1, 60, 60, 56]             112             112\n",
      "                Linear-3      [1, 60, 60, 56]           3,192           3,192\n",
      "    TransformerEncoder-4      [1, 60, 60, 56]         210,864         210,864\n",
      "                Conv2d-5     [1, 224, 60, 60]          12,768          12,768\n",
      "                  GELU-6     [1, 224, 60, 60]               0               0\n",
      "                Conv2d-7     [1, 224, 60, 60]           2,240           2,240\n",
      "                Conv2d-8      [1, 56, 60, 60]          12,600          12,600\n",
      "             LayerNorm-9      [1, 60, 60, 56]             112             112\n",
      "               Linear-10      [1, 60, 60, 56]           3,192           3,192\n",
      "   TransformerEncoder-11      [1, 60, 60, 56]         210,864         210,864\n",
      "               Conv2d-12     [1, 224, 60, 60]          12,768          12,768\n",
      "                 GELU-13     [1, 224, 60, 60]               0               0\n",
      "               Conv2d-14     [1, 224, 60, 60]           2,240           2,240\n",
      "               Conv2d-15      [1, 56, 60, 60]          12,600          12,600\n",
      "            LayerNorm-16      [1, 60, 60, 56]             112             112\n",
      "               Linear-17      [1, 60, 60, 56]           3,192           3,192\n",
      "   TransformerEncoder-18      [1, 60, 60, 56]         210,864         210,864\n",
      "               Conv2d-19     [1, 224, 60, 60]          12,768          12,768\n",
      "                 GELU-20     [1, 224, 60, 60]               0               0\n",
      "               Conv2d-21     [1, 224, 60, 60]           2,240           2,240\n",
      "               Conv2d-22      [1, 56, 60, 60]          12,600          12,600\n",
      "               Conv2d-23      [1, 12, 60, 60]          12,108          12,108\n",
      "==============================================================================\n",
      "Total params: 739,004\n",
      "Trainable params: 739,004\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 203.3676288\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Expanded-windowed IREncoder, d = 42, window = 8, layer = 6*4=24, head = 4\n",
    "device = torch.device('cuda')\n",
    "irencoder = ExpandedWindowedIREncoder(img_res=60, d_embed=56, n_layer=[6,6,6], n_head=4,\n",
    "                                      hidden_dim_rate=2, conv_hidden_rate=1, window_size=12, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 60, 60, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(640, 360) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1      [1, 48, 60, 60]           1,344           1,344\n",
      "             LayerNorm-2      [1, 60, 60, 48]              96              96\n",
      "                Linear-3      [1, 60, 60, 48]           2,352           2,352\n",
      "    TransformerEncoder-4      [1, 60, 60, 48]         159,336         159,336\n",
      "                Conv2d-5     [1, 192, 60, 60]           9,408           9,408\n",
      "                  GELU-6     [1, 192, 60, 60]               0               0\n",
      "                Conv2d-7     [1, 192, 60, 60]           1,920           1,920\n",
      "                Conv2d-8      [1, 48, 60, 60]           9,264           9,264\n",
      "             LayerNorm-9      [1, 60, 60, 48]              96              96\n",
      "               Linear-10      [1, 60, 60, 48]           2,352           2,352\n",
      "   TransformerEncoder-11      [1, 60, 60, 48]         159,336         159,336\n",
      "               Conv2d-12     [1, 192, 60, 60]           9,408           9,408\n",
      "                 GELU-13     [1, 192, 60, 60]               0               0\n",
      "               Conv2d-14     [1, 192, 60, 60]           1,920           1,920\n",
      "               Conv2d-15      [1, 48, 60, 60]           9,264           9,264\n",
      "            LayerNorm-16      [1, 60, 60, 48]              96              96\n",
      "               Linear-17      [1, 60, 60, 48]           2,352           2,352\n",
      "   TransformerEncoder-18      [1, 60, 60, 48]         159,336         159,336\n",
      "               Conv2d-19     [1, 192, 60, 60]           9,408           9,408\n",
      "                 GELU-20     [1, 192, 60, 60]               0               0\n",
      "               Conv2d-21     [1, 192, 60, 60]           1,920           1,920\n",
      "               Conv2d-22      [1, 48, 60, 60]           9,264           9,264\n",
      "            LayerNorm-23      [1, 60, 60, 48]              96              96\n",
      "               Linear-24      [1, 60, 60, 48]           2,352           2,352\n",
      "   TransformerEncoder-25      [1, 60, 60, 48]         159,336         159,336\n",
      "               Conv2d-26     [1, 192, 60, 60]           9,408           9,408\n",
      "                 GELU-27     [1, 192, 60, 60]               0               0\n",
      "               Conv2d-28     [1, 192, 60, 60]           1,920           1,920\n",
      "               Conv2d-29      [1, 48, 60, 60]           9,264           9,264\n",
      "               Conv2d-30      [1, 12, 60, 60]          10,380          10,380\n",
      "==============================================================================\n",
      "Total params: 741,228\n",
      "Trainable params: 741,228\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 211.3523712\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Expanded-windowed IREncoder, d = 42, window = 8, layer = 6*4=24, head = 4\n",
    "device = torch.device('cuda')\n",
    "irencoder = ExpandedWindowedIREncoder(img_res=60, d_embed=48, n_layer=[6,6,6,6], n_head=3,\n",
    "                                      hidden_dim_rate=2, conv_hidden_rate=1, window_size=12, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 60, 60, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(640, 360) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------\n",
      "            Layer (type)         Output Shape         Param #     Tr. Param #\n",
      "==============================================================================\n",
      "                Conv2d-1      [1, 60, 60, 60]           1,680           1,680\n",
      "             LayerNorm-2      [1, 60, 60, 60]             120             120\n",
      "                Linear-3      [1, 60, 60, 36]           2,196           2,196\n",
      "    TransformerEncoder-4      [1, 60, 60, 36]         103,968         103,968\n",
      "                Conv2d-5      [1, 72, 60, 60]           2,664           2,664\n",
      "                  GELU-6      [1, 72, 60, 60]               0               0\n",
      "                Conv2d-7      [1, 72, 60, 60]             720             720\n",
      "                Conv2d-8      [1, 60, 60, 60]           4,380           4,380\n",
      "             LayerNorm-9      [1, 60, 60, 60]             120             120\n",
      "               Linear-10      [1, 60, 60, 48]           2,928           2,928\n",
      "   TransformerEncoder-11      [1, 60, 60, 48]         159,336         159,336\n",
      "               Conv2d-12      [1, 96, 60, 60]           4,704           4,704\n",
      "               Conv2d-13      [1, 96, 60, 60]             960             960\n",
      "               Conv2d-14      [1, 60, 60, 60]           5,820           5,820\n",
      "            LayerNorm-15      [1, 60, 60, 60]             120             120\n",
      "               Linear-16      [1, 60, 60, 48]           2,928           2,928\n",
      "   TransformerEncoder-17      [1, 60, 60, 48]         159,336         159,336\n",
      "               Conv2d-18      [1, 96, 60, 60]           4,704           4,704\n",
      "               Conv2d-19      [1, 96, 60, 60]             960             960\n",
      "               Conv2d-20      [1, 60, 60, 60]           5,820           5,820\n",
      "            LayerNorm-21      [1, 60, 60, 60]             120             120\n",
      "               Linear-22      [1, 60, 60, 60]           3,660           3,660\n",
      "   TransformerEncoder-23      [1, 60, 60, 60]         228,528         228,528\n",
      "               Conv2d-24     [1, 120, 60, 60]           7,320           7,320\n",
      "               Conv2d-25     [1, 120, 60, 60]           1,200           1,200\n",
      "               Conv2d-26      [1, 60, 60, 60]           7,260           7,260\n",
      "               Conv2d-27      [1, 12, 60, 60]          12,972          12,972\n",
      "==============================================================================\n",
      "Total params: 724,524\n",
      "Trainable params: 724,524\n",
      "Non-trainable params: 0\n",
      "------------------------------------------------------------------------------\n",
      "GFlops : 207.6558336\n"
     ]
    }
   ],
   "source": [
    "# Lightweight Expanded-windowed IREncoder, d = 42, window = 8, layer = 6*4=24, head = 4\n",
    "device = torch.device('cuda')\n",
    "irencoder = ExpandedWindowedIREncoder(img_res=60, d_embed=[36,48,48,60], n_layer=[6,6,6,6], n_head=3, hidden_dim_rate=2,\n",
    "                                      conv_hidden_rate=1, residual_hidden_rate=2, window_size=12, sr_upscale=2).to(device)\n",
    "\n",
    "print(pytorch_model_summary.summary(irencoder,\n",
    "                                    torch.zeros(1, 3, 60, 60, device=device),\n",
    "                                    show_input=False))\n",
    "\n",
    "print('GFlops :', irencoder.flops(640, 360) / 1000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for MultiScaleIREncoder:\n\tsize mismatch for feature_addition_modules.0.0.weight: copying a param with shape torch.Size([138, 46, 1, 1]) from checkpoint, the shape in current model is torch.Size([92, 46, 1, 1]).\n\tsize mismatch for feature_addition_modules.0.0.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.0.2.weight: copying a param with shape torch.Size([138, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([92, 1, 3, 3]).\n\tsize mismatch for feature_addition_modules.0.2.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.0.4.weight: copying a param with shape torch.Size([46, 138, 1, 1]) from checkpoint, the shape in current model is torch.Size([46, 92, 1, 1]).\n\tsize mismatch for feature_addition_modules.1.0.weight: copying a param with shape torch.Size([138, 46, 1, 1]) from checkpoint, the shape in current model is torch.Size([92, 46, 1, 1]).\n\tsize mismatch for feature_addition_modules.1.0.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.1.2.weight: copying a param with shape torch.Size([138, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([92, 1, 3, 3]).\n\tsize mismatch for feature_addition_modules.1.2.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.1.4.weight: copying a param with shape torch.Size([46, 138, 1, 1]) from checkpoint, the shape in current model is torch.Size([46, 92, 1, 1]).\n\tsize mismatch for feature_addition_modules.2.0.weight: copying a param with shape torch.Size([138, 46, 1, 1]) from checkpoint, the shape in current model is torch.Size([92, 46, 1, 1]).\n\tsize mismatch for feature_addition_modules.2.0.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.2.2.weight: copying a param with shape torch.Size([138, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([92, 1, 3, 3]).\n\tsize mismatch for feature_addition_modules.2.2.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.2.4.weight: copying a param with shape torch.Size([46, 138, 1, 1]) from checkpoint, the shape in current model is torch.Size([46, 92, 1, 1]).\n\tsize mismatch for feature_addition_modules.3.0.weight: copying a param with shape torch.Size([138, 46, 1, 1]) from checkpoint, the shape in current model is torch.Size([92, 46, 1, 1]).\n\tsize mismatch for feature_addition_modules.3.0.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.3.2.weight: copying a param with shape torch.Size([138, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([92, 1, 3, 3]).\n\tsize mismatch for feature_addition_modules.3.2.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.3.4.weight: copying a param with shape torch.Size([46, 138, 1, 1]) from checkpoint, the shape in current model is torch.Size([46, 92, 1, 1]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/coffeetumbler/projects/sr_trans/model_info.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/coffeetumbler/projects/sr_trans/model_info.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m MultiScaleIREncoder(img_res\u001b[39m=\u001b[39m\u001b[39m48\u001b[39m, d_embed\u001b[39m=\u001b[39m\u001b[39m46\u001b[39m, n_layer\u001b[39m=\u001b[39m[\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m4\u001b[39m], n_head\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/coffeetumbler/projects/sr_trans/model_info.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m                             hidden_dim_rate\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, window_size\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m, sr_upscale\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/coffeetumbler/projects/sr_trans/model_info.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m state_dict \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mlogs/X2/20230723_062415/state_dict/state_dict_epoch_1300.pt\u001b[39m\u001b[39m'\u001b[39m, map_location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/coffeetumbler/projects/sr_trans/model_info.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_state_dict(state_dict, strict\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/coffeetumbler/projects/sr_trans/model_info.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m sub_dict \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mweight\u001b[39m\u001b[39m'\u001b[39m : state_dict[\u001b[39m'\u001b[39m\u001b[39minitial_feature_mappings.0.weight\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/coffeetumbler/projects/sr_trans/model_info.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m : state_dict[\u001b[39m'\u001b[39m\u001b[39minitial_feature_mappings.0.bias\u001b[39m\u001b[39m'\u001b[39m]}\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/coffeetumbler/projects/sr_trans/model_info.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39minitial_feature_mapping\u001b[39m.\u001b[39mload_state_dict(sub_dict)\n",
      "File \u001b[0;32m~/anaconda3/envs/sr_trans/lib/python3.9/site-packages/torch/nn/modules/module.py:1406\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1402\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1403\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1405\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1406\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1407\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1408\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for MultiScaleIREncoder:\n\tsize mismatch for feature_addition_modules.0.0.weight: copying a param with shape torch.Size([138, 46, 1, 1]) from checkpoint, the shape in current model is torch.Size([92, 46, 1, 1]).\n\tsize mismatch for feature_addition_modules.0.0.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.0.2.weight: copying a param with shape torch.Size([138, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([92, 1, 3, 3]).\n\tsize mismatch for feature_addition_modules.0.2.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.0.4.weight: copying a param with shape torch.Size([46, 138, 1, 1]) from checkpoint, the shape in current model is torch.Size([46, 92, 1, 1]).\n\tsize mismatch for feature_addition_modules.1.0.weight: copying a param with shape torch.Size([138, 46, 1, 1]) from checkpoint, the shape in current model is torch.Size([92, 46, 1, 1]).\n\tsize mismatch for feature_addition_modules.1.0.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.1.2.weight: copying a param with shape torch.Size([138, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([92, 1, 3, 3]).\n\tsize mismatch for feature_addition_modules.1.2.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.1.4.weight: copying a param with shape torch.Size([46, 138, 1, 1]) from checkpoint, the shape in current model is torch.Size([46, 92, 1, 1]).\n\tsize mismatch for feature_addition_modules.2.0.weight: copying a param with shape torch.Size([138, 46, 1, 1]) from checkpoint, the shape in current model is torch.Size([92, 46, 1, 1]).\n\tsize mismatch for feature_addition_modules.2.0.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.2.2.weight: copying a param with shape torch.Size([138, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([92, 1, 3, 3]).\n\tsize mismatch for feature_addition_modules.2.2.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.2.4.weight: copying a param with shape torch.Size([46, 138, 1, 1]) from checkpoint, the shape in current model is torch.Size([46, 92, 1, 1]).\n\tsize mismatch for feature_addition_modules.3.0.weight: copying a param with shape torch.Size([138, 46, 1, 1]) from checkpoint, the shape in current model is torch.Size([92, 46, 1, 1]).\n\tsize mismatch for feature_addition_modules.3.0.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.3.2.weight: copying a param with shape torch.Size([138, 1, 3, 3]) from checkpoint, the shape in current model is torch.Size([92, 1, 3, 3]).\n\tsize mismatch for feature_addition_modules.3.2.bias: copying a param with shape torch.Size([138]) from checkpoint, the shape in current model is torch.Size([92]).\n\tsize mismatch for feature_addition_modules.3.4.weight: copying a param with shape torch.Size([46, 138, 1, 1]) from checkpoint, the shape in current model is torch.Size([46, 92, 1, 1])."
     ]
    }
   ],
   "source": [
    "# Parameters adopting from old model\n",
    "model = MultiScaleIREncoder(img_res=48, d_embed=46, n_layer=[4,4,4,4], n_head=2,\n",
    "                            hidden_dim_rate=2, window_size=8, sr_upscale=2)\n",
    "state_dict = torch.load('logs/X2/20230723_062415/state_dict/state_dict_epoch_1300.pt', map_location='cpu')\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "sub_dict = {'weight' : state_dict['initial_feature_mappings.0.weight'],\n",
    "            'bias' : state_dict['initial_feature_mappings.0.bias']}\n",
    "model.initial_feature_mapping.load_state_dict(sub_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.13659591258586\n",
      "0.9611594567132649\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dataloader = get_dataloader(setting='test', dataset='Set5')\n",
    "psnr, ssim = test(model, dataloader, None, len(dataloader), 2, torch.device('cpu'))\n",
    "print(psnr)\n",
    "print(ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'logs/X2/20230720_045925/model/model.pt')\n",
    "torch.save(model.state_dict(), 'logs/X2/20230720_045925/state_dict/state_dict_epoch_1540.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sr_trans",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
